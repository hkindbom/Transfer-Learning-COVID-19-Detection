{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning for COVID-19 Detection in X-Ray Images\n",
    "## DD2424 Deep Learning - Group Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter difference between current generated dataset and paper dataset to get the correct data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_lines(filename):\n",
    "    with open(filename) as f:\n",
    "        content = f.readlines()\n",
    "        \n",
    "    file_lines = [x.strip() for x in content]\n",
    "    return file_lines\n",
    "\n",
    "def filter_out_difference(correct_data_description, wrong_data_description):\n",
    "    correct_file_lines = get_file_lines(correct_data_description)\n",
    "    wrong_file_lines = get_file_lines(wrong_data_description)\n",
    "    \n",
    "    nr_missing_images = 0\n",
    "    \n",
    "    # Need to check substrings as wrong_file_description has longer lines\n",
    "    for correct_line in correct_file_lines:\n",
    "        if not any(correct_line in line for line in wrong_file_lines):\n",
    "            nr_missing_images += 1\n",
    "                \n",
    "    if nr_missing_images > 0:\n",
    "        print('you are missing: ', nr_missing_images, 'images')\n",
    "        return\n",
    "    print('you have all images in ', correct_data_description)\n",
    "    \n",
    "    new_correct_upd_lines = []\n",
    "    \n",
    "    for wrong_line in wrong_file_lines:\n",
    "        for correct_line in correct_file_lines:\n",
    "            if correct_line in wrong_line:\n",
    "                new_correct_upd_lines.append(wrong_line)\n",
    "                   \n",
    "    return new_correct_upd_lines\n",
    "    \n",
    "def write_line_list_to_file(file, line_list):\n",
    "    with open(file, 'w') as filehandle:\n",
    "        filehandle.writelines(\"%s\\n\" % line for line in line_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/test_split_v3.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a16264bc6684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcurrent_train_data_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/train_split_v3.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mupd_test_set_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_out_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaper_test_data_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_test_data_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mupd_train_set_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_out_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaper_train_data_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_train_data_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-deb54aa8b5f0>\u001b[0m in \u001b[0;36mfilter_out_difference\u001b[0;34m(correct_data_description, wrong_data_description)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfilter_out_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_data_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong_data_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcorrect_file_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_data_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mwrong_file_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrong_data_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnr_missing_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-deb54aa8b5f0>\u001b[0m in \u001b[0;36mget_file_lines\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_file_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfile_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/test_split_v3.txt'"
     ]
    }
   ],
   "source": [
    "paper_test_data_description = 'data/paper_dataset_specifications/test_COVIDx2.txt'\n",
    "paper_train_data_description = 'data/paper_dataset_specifications/train_COVIDx2.txt'\n",
    "\n",
    "current_test_data_description = 'data/test_split_v3.txt'\n",
    "current_train_data_description = 'data/train_split_v3.txt'\n",
    "\n",
    "upd_test_set_list = filter_out_difference(paper_test_data_description, current_test_data_description)\n",
    "upd_train_set_list = filter_out_difference(paper_train_data_description, current_train_data_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing updated and correct dataset description to txt file\n",
    "# write_line_list_to_file('data/correct_test_split.txt',upd_test_set_list)\n",
    "# write_line_list_to_file('data/correct_train_split.txt',upd_train_set_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving images to class partitioned directory\n",
    "mapping = {\n",
    "            'normal': 0,\n",
    "            'pneumonia': 1,\n",
    "            'COVID-19': 2}\n",
    "\n",
    "def get_label(img_desc_list):\n",
    "        for class_name in mapping:\n",
    "            if class_name in img_desc_list:\n",
    "                return mapping[class_name]\n",
    "\n",
    "current_dir = 'data/dataset/excess_train'\n",
    "new_dir = 'data/dataset/val/class'\n",
    "img_descriptions = get_file_lines('data/old_wrong_train_split_v3.txt')\n",
    "\n",
    "\n",
    "data_path = os.path.join(current_dir, '*g')\n",
    "images = glob.glob(data_path)\n",
    "\n",
    "for image_path in images:\n",
    "            image_name = image_path.replace(current_dir + '/', '')\n",
    "            for img_desc in img_descriptions:\n",
    "                if image_name in img_desc:\n",
    "                    img_desc_list = img_desc.split()\n",
    "                    label = get_label(img_desc_list)\n",
    "                    os.rename(image_path, new_dir +str(label) + '/' + image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for handling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much of this class in unnecessary now adays\n",
    "class Dataset:\n",
    "    def __init__(\n",
    "            self,\n",
    "            test_img_dir,\n",
    "            train_img_dir,\n",
    "            test_img_descriptions_file,\n",
    "            train_img_descriptions_file,\n",
    "            input_shape = (224, 224),\n",
    "            batch_size = 10\n",
    "                 ):\n",
    "        self.test_img_dir = test_img_dir\n",
    "        self.train_img_dir = train_img_dir\n",
    "        self.test_img_descriptions = get_file_lines(test_img_descriptions_file)\n",
    "        self.train_img_descriptions = get_file_lines(train_img_descriptions_file)\n",
    "        self.input_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_nr = 1\n",
    "        self.max_batch = len(self.train_img_descriptions) // self.batch_size\n",
    "        self.mapping = {\n",
    "                'normal': 0,\n",
    "                'pneumonia': 1,\n",
    "                'COVID-19': 2}\n",
    "\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.x_batch = None\n",
    "        self.y_batch = None\n",
    "\n",
    "    \n",
    "    def get_current_batch(self):\n",
    "        return self.x_batch, self.y_batch\n",
    "    \n",
    "    def _get_class_dist(self, y):\n",
    "        class_dist = {}\n",
    "        for class_name in self.mapping:\n",
    "            class_dist[class_name] = np.count_nonzero(y == self.mapping[class_name])\n",
    "        return class_dist\n",
    "\n",
    "    def get_test_class_dist(self):\n",
    "        test_class_dist = self._get_class_dist(self.y_test)\n",
    "\n",
    "        return test_class_dist\n",
    "\n",
    "    def read_test_data(self):\n",
    "        self.x_test, self.y_test = self._read_correct_images(self.test_img_dir, self.test_img_descriptions)\n",
    "\n",
    "    def _get_label(self, img_desc_list):\n",
    "        for class_name in self.mapping:\n",
    "            if class_name in img_desc_list:\n",
    "                return self.mapping[class_name]\n",
    "            \n",
    "    # Must load training data in batches since memory error otherwise    \n",
    "    def next_train_batch(self):\n",
    "        \n",
    "        if self.batch_nr == self.max_batch:\n",
    "            print('No data left')\n",
    "            return [], []\n",
    "        \n",
    "        start_img = (self.batch_nr-1) * self.batch_size\n",
    "        end_img = (self.batch_nr) * self.batch_size        \n",
    "                \n",
    "        batch_descriptions = self.train_img_descriptions[start_img: end_img]\n",
    "        \n",
    "        self.x_batch, self.y_batch = self._read_correct_images(self.train_img_dir, batch_descriptions)\n",
    "        \n",
    "        self.batch_nr += 1\n",
    "        \n",
    "\n",
    "    def _read_correct_images(self, img_dir, img_descriptions):\n",
    "        data_path = os.path.join(img_dir, '*g')\n",
    "        images = glob.glob(data_path)\n",
    "        \n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        \n",
    "        for image_path in images:\n",
    "            image_name = image_path.replace(img_dir + '/', '')\n",
    "            for img_desc in img_descriptions:\n",
    "                if image_name in img_desc:\n",
    "                    img_desc_list = img_desc.split()\n",
    "                    label = self._get_label(img_desc_list)\n",
    "                    y_list.append(label)\n",
    "\n",
    "                    img_array = cv2.imread(image_path)\n",
    "                    resized_img_array = cv2.resize(img_array, self.input_shape)\n",
    "                    x_list.append(resized_img_array)\n",
    "                    \n",
    "        y_array = np.array(y_list)\n",
    "        x_array = np.array(x_list)        \n",
    "\n",
    "        return x_array, y_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normal': 0, 'pneumonia': 0, 'COVID-19': 0}\n"
     ]
    }
   ],
   "source": [
    "test_data = 'data/dataset/test'\n",
    "test_data_description = 'data/correct_test_split.txt'\n",
    "\n",
    "train_data = 'data/dataset/train'\n",
    "train_data_description = 'data/correct_train_split.txt'\n",
    "\n",
    "dataset = Dataset(\n",
    "        test_data,\n",
    "        train_data,\n",
    "        test_data_description,\n",
    "        train_data_description\n",
    "       )\n",
    "\n",
    "# Read test data\n",
    "dataset.read_test_data()\n",
    "\n",
    "print(dataset.get_test_class_dist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof of concept with simple ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained VGG-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing model with freezed weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing packages"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 7,
>>>>>>> c269eb542dc78dfe0843b4b16cd0d798c8145602
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import models, layers, optimizers\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image directories, constants, use of generator and use of validation data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 8,
>>>>>>> c269eb542dc78dfe0843b4b16cd0d798c8145602
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Image import/process can be done using ImageDataGenerator, which enables easy data augmentation if we wish.\n",
    "If more suitable, put use_generator=false and specify all x and y\"\"\" \n",
    "\n",
    "# constants as in report\n",
    "img_size = 224 # double check in report\n",
    "learning_rate=2e-5\n",
    "epochs = 3 # in report 22\n",
    "batch_size = 8\n",
    "factor=0.7 # used in callback\n",
    "patience = 5 # used in callback\n",
    "optimizer='Adam'\n",
    "\n",
    "# adjust for number of samples\n",
    "nb_train_samples = 20\n",
    "nb_val_samples = 12\n",
    "\n",
    "# specify use of validation and/or generator feature\n",
    "use_generator = True\n",
    "use_validation = True \n",
    "use_callbacks = False\n",
    "\n",
    "if use_generator:\n",
    "    train_dir = 'data/dataset/johanna_testdata/train'\n",
    "    val_dir = 'data/dataset/johanna_testdata/val'\n",
    "    test_dir = 'data/dataset/johanna_testdata/test'\n",
    "    \n",
    "if not use_generator: \n",
    "    x_train, y_train = None, None\n",
    "    x_test, y_test = None, None\n",
    "    val_data = None \n",
    "    \n",
    "if use_callbacks: \n",
    "    callbacks = [ReduceLROnPlateau(\n",
    "    monitor='loss', \n",
    "    factor=factor, \n",
    "    patience=patience, \n",
    "    verbose=0)]\n",
    "\n",
    "if not use_callbacks:\n",
    "    callbacks = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating model and freezing weights"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 41,458,499\n",
      "Trainable params: 33,823,235\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
>>>>>>> c269eb542dc78dfe0843b4b16cd0d798c8145602
   "source": [
    "#create model and freeze all but last conv block\n",
    "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "for layer in vgg_conv.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# model = \"the shell\", adding VGG network and extra layers to model\n",
    "model = models.Sequential() \n",
    "model.add(vgg_conv)\n",
    "model.add(layers.Flatten()) # in the report, this results in output shape 100,352 instead of 25,088\n",
    "model.add(layers.Dense(1024))\n",
    "model.add(layers.Dense(1024))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# summerize and compile\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run if ImageDataGenerator() is used to process images:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 3 classes.\n",
      "Found 9 images belonging to 3 classes.\n",
      "Found 12 images belonging to 3 classes.\n",
      "Generators generated :-)\n",
      "Model fine-tuned\n",
      "Model evaluated\n"
     ]
    }
   ],
>>>>>>> c269eb542dc78dfe0843b4b16cd0d798c8145602
   "source": [
    "if use_generator: \n",
    "    datagen = ImageDataGenerator()\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "\n",
    "    test_generator = datagen.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "\n",
    "    if use_validation:\n",
    "        val_generator = datagen.flow_from_directory(\n",
    "            val_dir,\n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "    else:\n",
    "        val_generator = None\n",
    "        \n",
    "    print(\"Generators generated :-)\")\n",
    "    \n",
    "    # fine-tune model\n",
    "    history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=nb_val_samples // batch_size, \n",
    "        verbose=0, \n",
    "        callbacks = callbacks)\n",
    "    \n",
    "    print(\"Model fine-tuned\")\n",
    "    \n",
    "    # evaluate model\n",
    "    result = model.evaluate_generator(test_generator)\n",
    "    \n",
    "    print(\"Model evaluated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run if ImageDataGenerator is NOT used to process images: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_generator:\n",
    "    model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs,\n",
    "        validation_data=val_data,\n",
    "        validation_steps= nb_val_samples // batch_size,\n",
    "        verbose=0\n",
    "        callbacks = [callback])\n",
    "    \n",
    "    result = model.evaluate(\n",
    "        x=x_test, \n",
    "        y=y_test, \n",
    "        batch_size=batch_size, \n",
    "        verbose=0)\n",
    "else: \n",
    "    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print accuracy for model with frozen weights"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
=======
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "accuracy 0.3333333432674408\n"
     ]
    }
   ],
>>>>>>> c269eb542dc78dfe0843b4b16cd0d798c8145602
   "source": [
    "print(\"Results:\")\n",
    "print(model.metrics_names[1], result[1])\n",
    "#print(model.metrics_names[2], result[2])\n",
    "#prediction = model.predict_generator(test_generator)\n",
    "#print(prediction)\n",
    "#model.save('transfer_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing model with no frozen weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annars finns U-net https://github.com/zhixuhao/unet\n",
    "\n",
    "# https://pythonprogramming.net/introduction-deep-learning-python-tensorflow-keras/\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-dc073df45c24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#(x_train, y_train),(x_test, y_test) = mnist.load_data()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# Import and preprocess data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "#(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_test, y_test = dataset.read_test_data()\n",
    "x_train, y_train = dataset.next_train_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Vizualise data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0],cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten()) # Flattens image to one column\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) # Fully connected\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax)) # Final output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize and fit\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=3)\n",
    "\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "print(np.argmax(predictions[0]))\n",
    "\n",
    "plt.imshow(x_test[0],cmap=plt.cm.binary)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
